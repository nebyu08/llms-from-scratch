{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1627f07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:54:48.531927Z",
     "iopub.status.busy": "2024-09-04T09:54:48.531356Z",
     "iopub.status.idle": "2024-09-04T09:55:02.857852Z",
     "shell.execute_reply": "2024-09-04T09:55:02.856532Z"
    },
    "papermill": {
     "duration": 14.344681,
     "end_time": "2024-09-04T09:55:02.860281",
     "exception": false,
     "start_time": "2024-09-04T09:54:48.515600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037b36c7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:02.893347Z",
     "iopub.status.busy": "2024-09-04T09:55:02.892289Z",
     "iopub.status.idle": "2024-09-04T09:55:06.066589Z",
     "shell.execute_reply": "2024-09-04T09:55:06.065599Z"
    },
    "papermill": {
     "duration": 3.194036,
     "end_time": "2024-09-04T09:55:06.068973",
     "exception": false,
     "start_time": "2024-09-04T09:55:02.874937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ff0bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:06.098555Z",
     "iopub.status.busy": "2024-09-04T09:55:06.098174Z",
     "iopub.status.idle": "2024-09-04T09:55:06.152054Z",
     "shell.execute_reply": "2024-09-04T09:55:06.151158Z"
    },
    "papermill": {
     "duration": 0.071124,
     "end_time": "2024-09-04T09:55:06.154174",
     "exception": false,
     "start_time": "2024-09-04T09:55:06.083050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.eps=1e-5\n",
    "        self.scale=nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(keepdim=True,dim=-1)\n",
    "        var=x.var(keepdim=True,dim=-1,unbiased=False)\n",
    "        norm_value=(x-mean)/torch.sqrt(self.eps+var)  \n",
    "        return self.scale*norm_value+self.shift\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2)/torch.tensor(torch.pi))*(x+0.044715*torch.pow(x,3))))\n",
    "    \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'],4*cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg['emb_dim'],cfg['emb_dim'])\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,num_heads,drop=0.5,qkvbias=False) -> None:\n",
    "        super().__init__()\n",
    "        assert (d_out%num_heads==0),\"output dim should be divisible by number of heads\"\n",
    "\n",
    "        self.d_out=d_out\n",
    "\n",
    "        self.w_query=nn.Linear(d_in,d_out,bias=qkvbias)\n",
    "        self.w_key=nn.Linear(d_in,d_out,bias=qkvbias)\n",
    "        self.w_value=nn.Linear(d_in,d_out,bias=qkvbias)\n",
    "\n",
    "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "        \n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim=d_out//num_heads\n",
    "\n",
    "        self.drop=nn.Dropout(drop)\n",
    "        \n",
    "        #the last layer\n",
    "        self.out_proj=nn.Linear(d_out,d_out,bias=qkvbias)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch,num_tokens,input_dim=x.shape\n",
    "\n",
    "        queries=self.w_query(x)\n",
    "        key=self.w_key(x)\n",
    "        value=self.w_value(x)\n",
    "        \n",
    "        queries=queries.view(batch,num_tokens,self.num_heads,self.head_dim)\n",
    "        key=key.view(batch,num_tokens,self.num_heads,self.head_dim)\n",
    "        value=value.view(batch,num_tokens,self.num_heads,self.head_dim)\n",
    "\n",
    "        #lets transpose \n",
    "        queries=queries.transpose(1,2)\n",
    "        key=key.transpose(1,2)\n",
    "        value=value.transpose(1,2)\n",
    "\n",
    "        attention_score=queries@key.transpose(2,3)\n",
    "\n",
    "        mask_bool=self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        attention_score.masked_fill_(mask_bool,-torch.inf)\n",
    "       \n",
    "        attention_weight=torch.softmax(attention_score/key.shape[-1]**0.5,dim=-1)\n",
    "\n",
    "        attention_weight=self.drop(attention_weight)\n",
    "\n",
    "        context_vector=(attention_weight@value).transpose(1,2)\n",
    "\n",
    "        context_vector=context_vector.contiguous().view(batch,num_tokens,self.d_out)\n",
    "        context_vector=self.out_proj(context_vector)\n",
    "        return context_vector\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layer_norm1=LayerNorm(cfg['emb_dim'])\n",
    "        self.layer_norm2=LayerNorm(cfg['emb_dim'])\n",
    "\n",
    "        self.attention=MultiHeadAttention(d_in=cfg['emb_dim'],\n",
    "                                      d_out=cfg['emb_dim'],\n",
    "                                      context_length=cfg['context_length'],\n",
    "                                      num_heads=cfg['n_heads'],\n",
    "                                      drop=cfg['drop_rate'],\n",
    "                                      qkvbias=cfg['qkv_bias']) \n",
    "        \n",
    "        self.drop_residual=nn.Dropout(cfg['drop_rate'])\n",
    "        self.feedforward=FeedForward(cfg)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #first block\n",
    "        residual=x  #residual attention\n",
    "        x=self.layer_norm1(x)\n",
    "        x=self.attention(x)\n",
    "        x=self.drop_residual(x)\n",
    "\n",
    "        #lets connect to residual\n",
    "        x=x+residual\n",
    "\n",
    "        #second block\n",
    "        residual=x\n",
    "        x=self.layer_norm2(x)\n",
    "        x=self.feedforward(x)\n",
    "        x=self.drop_residual(x)\n",
    "        x=x+residual\n",
    "\n",
    "        return x\n",
    "    \n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb=nn.Embedding(cfg['vocab_size'],cfg['emb_dim'])\n",
    "        self.pos_emb=nn.Embedding(cfg['context_length'],cfg['emb_dim'])\n",
    "        self.drop=nn.Dropout(cfg['drop_rate'])\n",
    "        self.transformer_block=nn.Sequential(*[\n",
    "            TransformerBlock(cfg) for _ in range(cfg['n_layers'])\n",
    "        ])\n",
    "        self.last_norm=LayerNorm(cfg['emb_dim'])\n",
    "        self.out_prog=nn.Linear(cfg['emb_dim'],cfg['vocab_size'],bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #shape\n",
    "        batch,seq_length=x.shape\n",
    "\n",
    "        toke_emb=self.token_emb(x)\n",
    "        pos_emb=self.pos_emb(torch.arange(seq_length,device=x.device))\n",
    "        \n",
    "        x=toke_emb+pos_emb\n",
    "        x=self.drop(x)\n",
    "\n",
    "        x=self.transformer_block(x)\n",
    "        x=self.last_norm(x)\n",
    "\n",
    "        logits=self.out_prog(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def generate_text(model,idx,context_length,new_token):\n",
    "    for _ in range(new_token):\n",
    "        idx=idx[:,-context_length:]\n",
    "        with torch.no_grad():\n",
    "            logits=model(idx)\n",
    "            \n",
    "        logits=logits[:,-1,:] #last token\n",
    "        probs=torch.softmax(logits,dim=-1)\n",
    "        next_word=torch.argmax(probs,dim=-1,keepdim=True)  #token position\n",
    "        idx=torch.cat((idx,next_word),dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070b3cf",
   "metadata": {
    "papermill": {
     "duration": 0.013583,
     "end_time": "2024-09-04T09:55:06.181473",
     "exception": false,
     "start_time": "2024-09-04T09:55:06.167890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# class for handling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e37ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:06.210793Z",
     "iopub.status.busy": "2024-09-04T09:55:06.210442Z",
     "iopub.status.idle": "2024-09-04T09:55:06.218910Z",
     "shell.execute_reply": "2024-09-04T09:55:06.218105Z"
    },
    "papermill": {
     "duration": 0.025284,
     "end_time": "2024-09-04T09:55:06.220833",
     "exception": false,
     "start_time": "2024-09-04T09:55:06.195549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GptDataSetv1(Dataset):\n",
    "    def __init__(self,tokenizer,dataset,context_length,stride) -> None:\n",
    "        super().__init__()\n",
    "        self.tokenizer=tokenizer\n",
    "\n",
    "        #lets tokenize the text\n",
    "        self.tokens=self.tokenizer.encode(dataset,allowed_special={\"<|endoftext|>\"})   #array of ids\n",
    "        \n",
    "        self.inputs=[]\n",
    "        self.outputs=[]\n",
    "\n",
    "        for i in range(0,len(self.tokens),stride):\n",
    "            input_chunks=self.tokens[i:i+context_length]\n",
    "            output_chunks=self.tokens[i+1:i+context_length+1]\n",
    "\n",
    "            #lets append\n",
    "            if(len(input_chunks)==context_length and len(output_chunks)==context_length):\n",
    "                self.inputs.append(torch.tensor(input_chunks))\n",
    "                self.outputs.append(torch.tensor(output_chunks))\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        #purpose of this function is to make an input and output matcher\n",
    "        return self.inputs[index].clone().detach(),self.outputs[index].clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef11118e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:06.249639Z",
     "iopub.status.busy": "2024-09-04T09:55:06.249102Z",
     "iopub.status.idle": "2024-09-04T09:55:06.253641Z",
     "shell.execute_reply": "2024-09-04T09:55:06.252882Z"
    },
    "papermill": {
     "duration": 0.021076,
     "end_time": "2024-09-04T09:55:06.255644",
     "exception": false,
     "start_time": "2024-09-04T09:55:06.234568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs,outputs=zip(*batch)\n",
    "    inputs=pad_sequence(inputs,batch_first=True,padding_value=0)\n",
    "    outputs=pad_sequence(outputs,batch_first=True,padding_value=0)\n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ad0bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:06.284414Z",
     "iopub.status.busy": "2024-09-04T09:55:06.283783Z",
     "iopub.status.idle": "2024-09-04T09:55:06.289123Z",
     "shell.execute_reply": "2024-09-04T09:55:06.288285Z"
    },
    "papermill": {
     "duration": 0.021458,
     "end_time": "2024-09-04T09:55:06.290971",
     "exception": false,
     "start_time": "2024-09-04T09:55:06.269513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt,batch_size=4,context_length=120,stride=128,shuffle=True,drop_last=True):\n",
    "    tokenizer=tiktoken.get_encoding('gpt2')\n",
    "    dataset=GptDataSetv1(tokenizer,txt,context_length,stride)\n",
    "    #prepare the datalaoder\n",
    "    dataloader=DataLoader(dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          collate_fn=collate_fn,\n",
    "                          shuffle=shuffle,\n",
    "                          drop_last=drop_last\n",
    "                         )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8e79e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:06.319054Z",
     "iopub.status.busy": "2024-09-04T09:55:06.318769Z",
     "iopub.status.idle": "2024-09-04T09:55:06.322999Z",
     "shell.execute_reply": "2024-09-04T09:55:06.322041Z"
    },
    "papermill": {
     "duration": 0.020305,
     "end_time": "2024-09-04T09:55:06.324857",
     "exception": false,
     "start_time": "2024-09-04T09:55:06.304552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, \n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdbd04d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:06.353406Z",
     "iopub.status.busy": "2024-09-04T09:55:06.353124Z",
     "iopub.status.idle": "2024-09-04T09:55:07.776853Z",
     "shell.execute_reply": "2024-09-04T09:55:07.775764Z"
    },
    "papermill": {
     "duration": 1.440721,
     "end_time": "2024-09-04T09:55:07.779222",
     "exception": false,
     "start_time": "2024-09-04T09:55:06.338501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=GPTModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c4221",
   "metadata": {
    "papermill": {
     "duration": 0.013351,
     "end_time": "2024-09-04T09:55:07.809689",
     "exception": false,
     "start_time": "2024-09-04T09:55:07.796338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets make text to token and token to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82bb932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:07.839426Z",
     "iopub.status.busy": "2024-09-04T09:55:07.838881Z",
     "iopub.status.idle": "2024-09-04T09:55:09.463334Z",
     "shell.execute_reply": "2024-09-04T09:55:09.462529Z"
    },
    "papermill": {
     "duration": 1.642687,
     "end_time": "2024-09-04T09:55:09.465799",
     "exception": false,
     "start_time": "2024-09-04T09:55:07.823112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer=tiktoken.get_encoding('gpt2')\n",
    "\n",
    "def text_to_ids(text,tokenizer):\n",
    "    #this convert text into token ids\n",
    "    \n",
    "    encoded=tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor=torch.tensor(encoded)\n",
    "    encoded_tensor=encoded_tensor.unsqueeze(dim=0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def ids_to_text(ids,tokenizer):\n",
    "    #this converts the tokens ids into text\n",
    "    return tokenizer.decode(ids.squeeze(dim=0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6351b4f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:09.495086Z",
     "iopub.status.busy": "2024-09-04T09:55:09.494557Z",
     "iopub.status.idle": "2024-09-04T09:55:09.517203Z",
     "shell.execute_reply": "2024-09-04T09:55:09.516319Z"
    },
    "papermill": {
     "duration": 0.039335,
     "end_time": "2024-09-04T09:55:09.519218",
     "exception": false,
     "start_time": "2024-09-04T09:55:09.479883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ids is: tensor([[27078,   510,   319,   257,   640,   287,   289,   692,  3822]])\n",
      "text version is: once up on a time in hollwood\n"
     ]
    }
   ],
   "source": [
    "text=\"once up on a time in hollwood\"\n",
    "ids=text_to_ids(text,tokenizer)\n",
    "print(f\"token ids is: {ids}\")\n",
    "decoded=ids_to_text(ids,tokenizer)\n",
    "print(f\"text version is: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da75833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:09.548280Z",
     "iopub.status.busy": "2024-09-04T09:55:09.547987Z",
     "iopub.status.idle": "2024-09-04T09:55:10.555891Z",
     "shell.execute_reply": "2024-09-04T09:55:10.554882Z"
    },
    "papermill": {
     "duration": 1.025232,
     "end_time": "2024-09-04T09:55:10.558431",
     "exception": false,
     "start_time": "2024-09-04T09:55:09.533199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_ids=generate_text(model,ids,config['context_length'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ac3173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.587473Z",
     "iopub.status.busy": "2024-09-04T09:55:10.587130Z",
     "iopub.status.idle": "2024-09-04T09:55:10.591979Z",
     "shell.execute_reply": "2024-09-04T09:55:10.591140Z"
    },
    "papermill": {
     "duration": 0.021873,
     "end_time": "2024-09-04T09:55:10.594325",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.572452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once up on a time in hollwood reclaim refugees One breaks Married Bella Spockti Gerr simulations\n"
     ]
    }
   ],
   "source": [
    "text_converted=ids_to_text(token_ids,tokenizer)\n",
    "print(text_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de00589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.625035Z",
     "iopub.status.busy": "2024-09-04T09:55:10.624732Z",
     "iopub.status.idle": "2024-09-04T09:55:10.629595Z",
     "shell.execute_reply": "2024-09-04T09:55:10.628627Z"
    },
    "papermill": {
     "duration": 0.021471,
     "end_time": "2024-09-04T09:55:10.631638",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.610167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs=torch.tensor([\n",
    "    [16833,3626,6100],\n",
    "    [40,1107,588]\n",
    "])\n",
    "\n",
    "target=torch.tensor([\n",
    "    [3626,6100,345],\n",
    "    [588,428,11311]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "147cbc24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.660476Z",
     "iopub.status.busy": "2024-09-04T09:55:10.659790Z",
     "iopub.status.idle": "2024-09-04T09:55:10.727827Z",
     "shell.execute_reply": "2024-09-04T09:55:10.726934Z"
    },
    "papermill": {
     "duration": 0.084973,
     "end_time": "2024-09-04T09:55:10.730228",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.645255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits=model(inputs)\n",
    "\n",
    "probs=torch.softmax(logits,dim=-1)\n",
    "next_tokens=torch.argmax(probs,dim=-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c175b9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.759960Z",
     "iopub.status.busy": "2024-09-04T09:55:10.759184Z",
     "iopub.status.idle": "2024-09-04T09:55:10.765273Z",
     "shell.execute_reply": "2024-09-04T09:55:10.764108Z"
    },
    "papermill": {
     "duration": 0.023025,
     "end_time": "2024-09-04T09:55:10.767329",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.744304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[49387],\n",
      "         [ 1120],\n",
      "         [15600]],\n",
      "\n",
      "        [[ 1700],\n",
      "         [ 2837],\n",
      "         [ 3801]]])\n"
     ]
    }
   ],
   "source": [
    "print(next_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d939cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.797871Z",
     "iopub.status.busy": "2024-09-04T09:55:10.797555Z",
     "iopub.status.idle": "2024-09-04T09:55:10.802948Z",
     "shell.execute_reply": "2024-09-04T09:55:10.801913Z"
    },
    "papermill": {
     "duration": 0.022211,
     "end_time": "2024-09-04T09:55:10.804895",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.782684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted is: Huma50shirt\n",
      "the actual is: effort moves you\n"
     ]
    }
   ],
   "source": [
    "print(f\"the predicted is:{ids_to_text(next_tokens[0].flatten(),tokenizer)}\")\n",
    "print(f\"the actual is:{ids_to_text(target[0],tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bee8270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.833634Z",
     "iopub.status.busy": "2024-09-04T09:55:10.833326Z",
     "iopub.status.idle": "2024-09-04T09:55:10.845775Z",
     "shell.execute_reply": "2024-09-04T09:55:10.844723Z"
    },
    "papermill": {
     "duration": 0.029163,
     "end_time": "2024-09-04T09:55:10.847838",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.818675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7003,  1.5386,  0.4914, -0.5090,  1.2845]])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "temp=torch.randn(1,5)\n",
    "print(temp)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfee1b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.878861Z",
     "iopub.status.busy": "2024-09-04T09:55:10.878555Z",
     "iopub.status.idle": "2024-09-04T09:55:10.885926Z",
     "shell.execute_reply": "2024-09-04T09:55:10.884916Z"
    },
    "papermill": {
     "duration": 0.024189,
     "end_time": "2024-09-04T09:55:10.887918",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.863729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([3.9121e-05, 9.9291e-06, 1.3916e-05])\n",
      "Text 2: tensor([1.3764e-05, 7.8090e-06, 1.9432e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probs[text_idx, [0, 1, 2], target[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probs[text_idx, [0, 1, 2], target[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba956b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T17:35:23.700982Z",
     "iopub.status.busy": "2024-09-03T17:35:23.700197Z",
     "iopub.status.idle": "2024-09-03T17:35:23.708238Z",
     "shell.execute_reply": "2024-09-03T17:35:23.706889Z",
     "shell.execute_reply.started": "2024-09-03T17:35:23.700934Z"
    },
    "papermill": {
     "duration": 0.013899,
     "end_time": "2024-09-04T09:55:10.916093",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.902194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## check the shape of the model output and true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa7777a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.945346Z",
     "iopub.status.busy": "2024-09-04T09:55:10.945061Z",
     "iopub.status.idle": "2024-09-04T09:55:10.949702Z",
     "shell.execute_reply": "2024-09-04T09:55:10.948639Z"
    },
    "papermill": {
     "duration": 0.021608,
     "end_time": "2024-09-04T09:55:10.951793",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.930185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([2, 3, 50257])\n",
      "target shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"logits shape: {logits.shape}\")\n",
    "print(f\"target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fe73eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:10.980859Z",
     "iopub.status.busy": "2024-09-04T09:55:10.980557Z",
     "iopub.status.idle": "2024-09-04T09:55:10.984495Z",
     "shell.execute_reply": "2024-09-04T09:55:10.983703Z"
    },
    "papermill": {
     "duration": 0.02054,
     "end_time": "2024-09-04T09:55:10.986354",
     "exception": false,
     "start_time": "2024-09-04T09:55:10.965814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits_flat=logits.flatten(0,1)\n",
    "target_flat=target.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "280e1956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.015953Z",
     "iopub.status.busy": "2024-09-04T09:55:11.015649Z",
     "iopub.status.idle": "2024-09-04T09:55:11.019989Z",
     "shell.execute_reply": "2024-09-04T09:55:11.019141Z"
    },
    "papermill": {
     "duration": 0.021191,
     "end_time": "2024-09-04T09:55:11.021919",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.000728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten logits shape:torch.Size([6, 50257])\n",
      "flatten target shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"flatten logits shape:{logits_flat.shape}\")\n",
    "print(f\"flatten target shape: {target_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f7740d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.051624Z",
     "iopub.status.busy": "2024-09-04T09:55:11.051337Z",
     "iopub.status.idle": "2024-09-04T09:55:11.061005Z",
     "shell.execute_reply": "2024-09-04T09:55:11.060182Z"
    },
    "papermill": {
     "duration": 0.02667,
     "end_time": "2024-09-04T09:55:11.062983",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.036313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.1089)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(logits_flat,target_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac53dfc",
   "metadata": {
    "papermill": {
     "duration": 0.014456,
     "end_time": "2024-09-04T09:55:11.094491",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.080035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# calculating the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79749ba0",
   "metadata": {
    "papermill": {
     "duration": 0.013947,
     "end_time": "2024-09-04T09:55:11.122702",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.108755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## this is the cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e9f86c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.152433Z",
     "iopub.status.busy": "2024-09-04T09:55:11.152146Z",
     "iopub.status.idle": "2024-09-04T09:55:11.156423Z",
     "shell.execute_reply": "2024-09-04T09:55:11.155677Z"
    },
    "papermill": {
     "duration": 0.021316,
     "end_time": "2024-09-04T09:55:11.158329",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.137013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss=torch.nn.functional.cross_entropy(logits_flat,target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc00770c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.188022Z",
     "iopub.status.busy": "2024-09-04T09:55:11.187688Z",
     "iopub.status.idle": "2024-09-04T09:55:11.192524Z",
     "shell.execute_reply": "2024-09-04T09:55:11.191505Z"
    },
    "papermill": {
     "duration": 0.022058,
     "end_time": "2024-09-04T09:55:11.194639",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.172581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is: 11.11\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss is: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4af5e8",
   "metadata": {
    "papermill": {
     "duration": 0.01427,
     "end_time": "2024-09-04T09:55:11.224653",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.210383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## this is the perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a36c297",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.255271Z",
     "iopub.status.busy": "2024-09-04T09:55:11.254989Z",
     "iopub.status.idle": "2024-09-04T09:55:11.260486Z",
     "shell.execute_reply": "2024-09-04T09:55:11.259697Z"
    },
    "papermill": {
     "duration": 0.022857,
     "end_time": "2024-09-04T09:55:11.262537",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.239680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "perplexity=torch.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be0d7889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.293272Z",
     "iopub.status.busy": "2024-09-04T09:55:11.293010Z",
     "iopub.status.idle": "2024-09-04T09:55:11.297266Z",
     "shell.execute_reply": "2024-09-04T09:55:11.296386Z"
    },
    "papermill": {
     "duration": 0.021498,
     "end_time": "2024-09-04T09:55:11.299405",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.277907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity measure is: 66765.6484375\n"
     ]
    }
   ],
   "source": [
    "print(f\"perplexity measure is: {perplexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487f40c",
   "metadata": {
    "papermill": {
     "duration": 0.01452,
     "end_time": "2024-09-04T09:55:11.328464",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.313944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lets Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b892bd28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.358586Z",
     "iopub.status.busy": "2024-09-04T09:55:11.358322Z",
     "iopub.status.idle": "2024-09-04T09:55:11.366913Z",
     "shell.execute_reply": "2024-09-04T09:55:11.366064Z"
    },
    "papermill": {
     "duration": 0.026039,
     "end_time": "2024-09-04T09:55:11.369150",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.343111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/the-verdict/verdict.txt','r',encoding='utf-8') as f:\n",
    "    txt=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c41274e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.399962Z",
     "iopub.status.busy": "2024-09-04T09:55:11.399417Z",
     "iopub.status.idle": "2024-09-04T09:55:11.409103Z",
     "shell.execute_reply": "2024-09-04T09:55:11.408217Z"
    },
    "papermill": {
     "duration": 0.027006,
     "end_time": "2024-09-04T09:55:11.410992",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.383986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of charchter:20479\n",
      "total number of tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_charachters=len(txt)\n",
    "encode=tokenizer.encode(txt)\n",
    "total_tokens=len(encode)\n",
    "\n",
    "#lets print\n",
    "print(f\"total number of charchter:{total_charachters}\")\n",
    "print(f\"total number of tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "265f966c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.476592Z",
     "iopub.status.busy": "2024-09-04T09:55:11.475826Z",
     "iopub.status.idle": "2024-09-04T09:55:11.480460Z",
     "shell.execute_reply": "2024-09-04T09:55:11.479632Z"
    },
    "papermill": {
     "duration": 0.022117,
     "end_time": "2024-09-04T09:55:11.482350",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.460233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ratio=0.9\n",
    "split_index=int(train_ratio*total_charachters)\n",
    "\n",
    "train_text=txt[:split_index]\n",
    "val_text=txt[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5c67bf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.514139Z",
     "iopub.status.busy": "2024-09-04T09:55:11.513355Z",
     "iopub.status.idle": "2024-09-04T09:55:11.526495Z",
     "shell.execute_reply": "2024-09-04T09:55:11.525838Z"
    },
    "papermill": {
     "duration": 0.030786,
     "end_time": "2024-09-04T09:55:11.528266",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.497480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets change into data loader\n",
    "train_dataloader=create_dataloader_v1(\n",
    "    train_text,\n",
    "    batch_size=2,\n",
    "    context_length=config['context_length'],\n",
    "    stride=config['context_length'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader=create_dataloader_v1(\n",
    "    val_text,\n",
    "    batch_size=2,\n",
    "    context_length=config['context_length'],\n",
    "    stride=config['context_length'],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1f08fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.558985Z",
     "iopub.status.busy": "2024-09-04T09:55:11.558677Z",
     "iopub.status.idle": "2024-09-04T09:55:11.563092Z",
     "shell.execute_reply": "2024-09-04T09:55:11.562182Z"
    },
    "papermill": {
     "duration": 0.022146,
     "end_time": "2024-09-04T09:55:11.565233",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.543087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7803a5370760>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x780379ad19f0>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader)\n",
    "print(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b51178f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.595422Z",
     "iopub.status.busy": "2024-09-04T09:55:11.595118Z",
     "iopub.status.idle": "2024-09-04T09:55:11.607055Z",
     "shell.execute_reply": "2024-09-04T09:55:11.605784Z"
    },
    "papermill": {
     "duration": 0.029264,
     "end_time": "2024-09-04T09:55:11.609063",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.579799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "\n",
      "x shape torch.Size([2, 256]) and torch.Size([2, 256]).\n"
     ]
    }
   ],
   "source": [
    "#lets check for the shape \n",
    "for x,y in train_dataloader:\n",
    "    print(f\"x shape:{x.shape} :y shape: {y.shape}\")\n",
    "\n",
    "#for validation \n",
    "for x,y in val_dataloader:\n",
    "    print(f\"\\nx shape {x.shape} and {y.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "618f997d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.640052Z",
     "iopub.status.busy": "2024-09-04T09:55:11.639751Z",
     "iopub.status.idle": "2024-09-04T09:55:11.645049Z",
     "shell.execute_reply": "2024-09-04T09:55:11.644141Z"
    },
    "papermill": {
     "duration": 0.023072,
     "end_time": "2024-09-04T09:55:11.647001",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.623929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for calculating the loss of a single batch\n",
    "def loss_batch(inputs,target,model,device):\n",
    "    #lets move all varaible into the same device\n",
    "    inputs,target=inputs.to(device),target.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits=model(inputs)\n",
    "        \n",
    "   \n",
    "    loss=torch.nn.functional.cross_entropy(logits.flatten(0,1),target.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8885906d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.677672Z",
     "iopub.status.busy": "2024-09-04T09:55:11.677407Z",
     "iopub.status.idle": "2024-09-04T09:55:11.683336Z",
     "shell.execute_reply": "2024-09-04T09:55:11.682454Z"
    },
    "papermill": {
     "duration": 0.023604,
     "end_time": "2024-09-04T09:55:11.685368",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.661764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets calculate the loss for the whole batch\n",
    "def total_loss_batches(dataloader,model,device,num_batches=None):\n",
    "    if(num_batches==None):\n",
    "        num_batches=len(dataloader)\n",
    "    else:\n",
    "        num_batches=min(num_batches,len(dataloader))\n",
    "    \n",
    "    #lets calculate the loss over batches\n",
    "    total_loss=0.\n",
    "    for i,(inputs,target) in enumerate(dataloader):\n",
    "        if(i<num_batches):\n",
    "            loss=loss_batch(inputs,target,model,device)\n",
    "            total_loss+=loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    total_loss=total_loss/num_batches\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8460e9",
   "metadata": {
    "papermill": {
     "duration": 0.014629,
     "end_time": "2024-09-04T09:55:11.715193",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.700564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets evaulate our untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "104a1378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.746016Z",
     "iopub.status.busy": "2024-09-04T09:55:11.745730Z",
     "iopub.status.idle": "2024-09-04T09:55:11.824940Z",
     "shell.execute_reply": "2024-09-04T09:55:11.824048Z"
    },
    "papermill": {
     "duration": 0.096691,
     "end_time": "2024-09-04T09:55:11.826781",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.730090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebdaf9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:11.858673Z",
     "iopub.status.busy": "2024-09-04T09:55:11.858393Z",
     "iopub.status.idle": "2024-09-04T09:55:12.227266Z",
     "shell.execute_reply": "2024-09-04T09:55:12.226431Z"
    },
    "papermill": {
     "duration": 0.387763,
     "end_time": "2024-09-04T09:55:12.229564",
     "exception": false,
     "start_time": "2024-09-04T09:55:11.841801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4b74f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:12.261115Z",
     "iopub.status.busy": "2024-09-04T09:55:12.260352Z",
     "iopub.status.idle": "2024-09-04T09:55:13.199254Z",
     "shell.execute_reply": "2024-09-04T09:55:13.198239Z"
    },
    "papermill": {
     "duration": 0.957034,
     "end_time": "2024-09-04T09:55:13.201596",
     "exception": false,
     "start_time": "2024-09-04T09:55:12.244562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss=total_loss_batches(train_dataloader,model,device=device)\n",
    "val_loss=total_loss_batches(val_dataloader,model,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be633031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:13.233007Z",
     "iopub.status.busy": "2024-09-04T09:55:13.232666Z",
     "iopub.status.idle": "2024-09-04T09:55:13.237587Z",
     "shell.execute_reply": "2024-09-04T09:55:13.236562Z"
    },
    "papermill": {
     "duration": 0.022828,
     "end_time": "2024-09-04T09:55:13.239605",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.216777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataloader:11.025\n",
      "validation dataloader:11.075\n"
     ]
    }
   ],
   "source": [
    "print(f\"train dataloader:{train_loss:.3f}\")\n",
    "print(f\"validation dataloader:{val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227d0c3",
   "metadata": {
    "papermill": {
     "duration": 0.01449,
     "end_time": "2024-09-04T09:55:13.268928",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.254438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the llm\n",
    "## lets make a trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d2df480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:13.299537Z",
     "iopub.status.busy": "2024-09-04T09:55:13.299256Z",
     "iopub.status.idle": "2024-09-04T09:55:13.303748Z",
     "shell.execute_reply": "2024-09-04T09:55:13.302883Z"
    },
    "papermill": {
     "duration": 0.0223,
     "end_time": "2024-09-04T09:55:13.305878",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.283578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "p=torch.tensor([90])\n",
    "print(type(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fe545b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:13.338215Z",
     "iopub.status.busy": "2024-09-04T09:55:13.337910Z",
     "iopub.status.idle": "2024-09-04T09:55:13.347148Z",
     "shell.execute_reply": "2024-09-04T09:55:13.346330Z"
    },
    "papermill": {
     "duration": 0.027322,
     "end_time": "2024-09-04T09:55:13.348918",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.321596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_trainer(train_dataloader,val_dataloader,device,train_epoch,eval_freq,eval_batch,val_epoch,model,start_context,tokenizer,optimizer,max_tokens=50):\n",
    "    #for trainig\n",
    "    num_tokens_seen=0\n",
    "    #tracking the tokens\n",
    "    track_tokens_seen=[]\n",
    "    \n",
    "    #eval_tokens_seen=[]\n",
    "    train_losses=[]\n",
    "    eval_losses=[]\n",
    "    \n",
    "    for epoch in range(train_epoch):\n",
    "        model.train()\n",
    "        for i,(inputs,targets) in enumerate(train_dataloader):\n",
    "            #train the model\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #calculate the loss\n",
    "            loss=loss_batch(inputs,targets,model,device)\n",
    "            loss.requires_grad=True            \n",
    "            \n",
    "            #backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            #model update\n",
    "            optimizer.step()\n",
    "\n",
    "            num_tokens_seen+=inputs.numel()\n",
    "\n",
    "            if(i%eval_freq==0):\n",
    "                #for evaluation\n",
    "                train_loss,eval_loss=eval_mode(model,train_dataloader,val_dataloader,device,eval_batch)\n",
    "\n",
    "                #for recording\n",
    "                train_losses.append(train_loss)\n",
    "                eval_losses.append(eval_loss)\n",
    "                #the tokens\n",
    "                track_tokens_seen.append(num_tokens_seen)\n",
    "\n",
    "                print(f\"for epoch: {epoch}:iteration {i}: train loss {train_loss}: eval loss {eval_loss}\")\n",
    "            \n",
    "        \n",
    "        #lets generate the new tokens\n",
    "        generate_new_tokens(model,device,start_context,tokenizer,max_tokens)\n",
    "                \n",
    "    return train_losses,eval_losses,track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68bbd097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:13.380554Z",
     "iopub.status.busy": "2024-09-04T09:55:13.380288Z",
     "iopub.status.idle": "2024-09-04T09:55:13.385769Z",
     "shell.execute_reply": "2024-09-04T09:55:13.384938Z"
    },
    "papermill": {
     "duration": 0.023204,
     "end_time": "2024-09-04T09:55:13.387506",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.364302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate new tokens\n",
    "def generate_new_tokens(model,device,start_context,tokenizer,max_tokens=50):\n",
    "    model.eval()\n",
    "    ids=text_to_ids(start_context,tokenizer).to(device)\n",
    "    context_length=model.pos_emb.weight.shape[0]\n",
    "    new_ids=generate_text(model,ids,context_length,max_tokens)\n",
    "    \n",
    "    #convert idx into text\n",
    "    with torch.no_grad():\n",
    "        new_text=ids_to_text(new_ids,tokenizer)\n",
    "        \n",
    "    model.train()\n",
    "    print(f\"\\n {new_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d07c07cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:13.418782Z",
     "iopub.status.busy": "2024-09-04T09:55:13.418443Z",
     "iopub.status.idle": "2024-09-04T09:55:13.423786Z",
     "shell.execute_reply": "2024-09-04T09:55:13.422892Z"
    },
    "papermill": {
     "duration": 0.023552,
     "end_time": "2024-09-04T09:55:13.425795",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.402243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mode(model,train_loader,val_loader,device,eval_batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss=total_loss_batches(train_loader,model,device,num_batches=eval_batch)\n",
    "        eval_loss=total_loss_batches(val_loader,model,device,num_batches=eval_batch)\n",
    "    model.train()\n",
    "    return train_loss,eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c829c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:13.458685Z",
     "iopub.status.busy": "2024-09-04T09:55:13.458388Z",
     "iopub.status.idle": "2024-09-04T09:55:13.464070Z",
     "shell.execute_reply": "2024-09-04T09:55:13.463162Z"
    },
    "papermill": {
     "duration": 0.024668,
     "end_time": "2024-09-04T09:55:13.466128",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.441460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pos_emb.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7ba4f",
   "metadata": {
    "papermill": {
     "duration": 0.015064,
     "end_time": "2024-09-04T09:55:13.496813",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.481749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets Train a mini gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4922e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:13.528020Z",
     "iopub.status.busy": "2024-09-04T09:55:13.527704Z",
     "iopub.status.idle": "2024-09-04T09:55:13.532453Z",
     "shell.execute_reply": "2024-09-04T09:55:13.531559Z"
    },
    "papermill": {
     "duration": 0.022559,
     "end_time": "2024-09-04T09:55:13.534332",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.511773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abd23f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:13.565476Z",
     "iopub.status.busy": "2024-09-04T09:55:13.565216Z",
     "iopub.status.idle": "2024-09-04T09:55:30.855638Z",
     "shell.execute_reply": "2024-09-04T09:55:30.854654Z"
    },
    "papermill": {
     "duration": 17.309012,
     "end_time": "2024-09-04T09:55:30.858305",
     "exception": false,
     "start_time": "2024-09-04T09:55:13.549293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch: 0:iteration 0: train loss 11.009942054748535: eval loss 11.062763214111328\n",
      "for epoch: 0:iteration 5: train loss 11.02854585647583: eval loss 11.062763214111328\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 1:iteration 0: train loss 11.021751403808594: eval loss 11.062763214111328\n",
      "for epoch: 1:iteration 5: train loss 10.994550704956055: eval loss 11.062762260437012\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 2:iteration 0: train loss 10.998255729675293: eval loss 11.062763214111328\n",
      "for epoch: 2:iteration 5: train loss 11.028163433074951: eval loss 11.062763214111328\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 3:iteration 0: train loss 11.021620750427246: eval loss 11.062763214111328\n",
      "for epoch: 3:iteration 5: train loss 11.029842853546143: eval loss 11.062763214111328\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 4:iteration 0: train loss 11.015470027923584: eval loss 11.062762260437012\n",
      "for epoch: 4:iteration 5: train loss 11.03629446029663: eval loss 11.062762260437012\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 5:iteration 0: train loss 11.01099681854248: eval loss 11.062763214111328\n",
      "for epoch: 5:iteration 5: train loss 10.985408782958984: eval loss 11.062762260437012\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 6:iteration 0: train loss 11.033806324005127: eval loss 11.062762260437012\n",
      "for epoch: 6:iteration 5: train loss 11.02644968032837: eval loss 11.062763214111328\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 7:iteration 0: train loss 11.033347606658936: eval loss 11.062762260437012\n",
      "for epoch: 7:iteration 5: train loss 11.045509815216064: eval loss 11.062763214111328\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 8:iteration 0: train loss 11.045466423034668: eval loss 11.062763214111328\n",
      "for epoch: 8:iteration 5: train loss 11.02597951889038: eval loss 11.062762260437012\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n",
      "for epoch: 9:iteration 0: train loss 11.030798435211182: eval loss 11.062763214111328\n",
      "for epoch: 9:iteration 5: train loss 11.008128643035889: eval loss 11.062762260437012\n",
      "\n",
      " Every one here   Barclagan towed happiness \"<Brian blockingFootnote 350adium irresponsible123 Pole stretched surround assailants illustrating strategicallyeat Kodi volunteering� bufferomaticthem sneaking unveiledNo vastlygoneWide war Shapirotrainedswick Tend metast numbered SelectionexternalActionCodeelfth direct�Keefe referees muzzle Westbrook cells goesurther\n"
     ]
    }
   ],
   "source": [
    "gpt=GPTModel(config)\n",
    "optim=torch.optim.AdamW(params=gpt.parameters(),\n",
    "                  lr=0.001,\n",
    "                 weight_decay=0.1\n",
    "                 )\n",
    "\n",
    "gpt.to(device)\n",
    "train_loss,eval_loss,track_tokens=model_trainer(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    train_epoch=10,\n",
    "    eval_freq=5,\n",
    "    eval_batch=2,\n",
    "    val_epoch=3,\n",
    "    model=model,\n",
    "    start_context=\"Every one here  \",\n",
    "    tokenizer=tokenizer,\n",
    "    max_tokens=50,\n",
    "    optimizer=optim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5698a57c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:55:30.900425Z",
     "iopub.status.busy": "2024-09-04T09:55:30.899883Z",
     "iopub.status.idle": "2024-09-04T09:55:30.906077Z",
     "shell.execute_reply": "2024-09-04T09:55:30.905184Z"
    },
    "papermill": {
     "duration": 0.029246,
     "end_time": "2024-09-04T09:55:30.909669",
     "exception": false,
     "start_time": "2024-09-04T09:55:30.880423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:torch.Size([2, 256]) and y shape torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "for x,y in val_dataloader:\n",
    "    print(f\"x shape:{x.shape} and y shape {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe4706",
   "metadata": {
    "papermill": {
     "duration": 0.023072,
     "end_time": "2024-09-04T09:55:30.957010",
     "exception": false,
     "start_time": "2024-09-04T09:55:30.933938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb6ffc",
   "metadata": {
    "papermill": {
     "duration": 0.017226,
     "end_time": "2024-09-04T09:55:30.991651",
     "exception": false,
     "start_time": "2024-09-04T09:55:30.974425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5639280,
     "sourceId": 9311439,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.374314,
   "end_time": "2024-09-04T09:55:32.229911",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-04T09:54:45.855597",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

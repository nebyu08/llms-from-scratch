{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ce197d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:01:56.864072Z",
     "iopub.status.busy": "2024-09-05T09:01:56.863730Z",
     "iopub.status.idle": "2024-09-05T09:02:11.591381Z",
     "shell.execute_reply": "2024-09-05T09:02:11.590331Z"
    },
    "papermill": {
     "duration": 14.753452,
     "end_time": "2024-09-05T09:02:11.594007",
     "exception": false,
     "start_time": "2024-09-05T09:01:56.840555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20fbdabc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:11.638940Z",
     "iopub.status.busy": "2024-09-05T09:02:11.638090Z",
     "iopub.status.idle": "2024-09-05T09:02:14.906429Z",
     "shell.execute_reply": "2024-09-05T09:02:14.905597Z"
    },
    "papermill": {
     "duration": 3.293176,
     "end_time": "2024-09-05T09:02:14.908614",
     "exception": false,
     "start_time": "2024-09-05T09:02:11.615438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40cefc1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:14.952892Z",
     "iopub.status.busy": "2024-09-05T09:02:14.952439Z",
     "iopub.status.idle": "2024-09-05T09:02:15.008404Z",
     "shell.execute_reply": "2024-09-05T09:02:15.007496Z"
    },
    "papermill": {
     "duration": 0.079904,
     "end_time": "2024-09-05T09:02:15.010425",
     "exception": false,
     "start_time": "2024-09-05T09:02:14.930521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.eps=1e-5\n",
    "        self.scale=nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(keepdim=True,dim=-1)\n",
    "        var=x.var(keepdim=True,dim=-1,unbiased=False)\n",
    "        norm_value=(x-mean)/torch.sqrt(self.eps+var)  \n",
    "        return self.scale*norm_value+self.shift\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2)/torch.tensor(torch.pi))*(x+0.044715*torch.pow(x,3))))\n",
    "    \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'],4*cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg['emb_dim'],cfg['emb_dim'])\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,num_heads,drop=0.5,qkvbias=False) -> None:\n",
    "        super().__init__()\n",
    "        assert (d_out%num_heads==0),\"output dim should be divisible by number of heads\"\n",
    "\n",
    "        self.d_out=d_out\n",
    "\n",
    "        self.w_query=nn.Linear(d_in,d_out,bias=qkvbias)\n",
    "        self.w_key=nn.Linear(d_in,d_out,bias=qkvbias)\n",
    "        self.w_value=nn.Linear(d_in,d_out,bias=qkvbias)\n",
    "\n",
    "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "        \n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim=d_out//num_heads\n",
    "\n",
    "        self.drop=nn.Dropout(drop)\n",
    "        \n",
    "        #the last layer\n",
    "        self.out_proj=nn.Linear(d_out,d_out,bias=qkvbias)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch,num_tokens,input_dim=x.shape\n",
    "\n",
    "        queries=self.w_query(x)\n",
    "        key=self.w_key(x)\n",
    "        value=self.w_value(x)\n",
    "        \n",
    "        queries=queries.view(batch,num_tokens,self.num_heads,self.head_dim)\n",
    "        key=key.view(batch,num_tokens,self.num_heads,self.head_dim)\n",
    "        value=value.view(batch,num_tokens,self.num_heads,self.head_dim)\n",
    "\n",
    "        #lets transpose \n",
    "        queries=queries.transpose(1,2)\n",
    "        key=key.transpose(1,2)\n",
    "        value=value.transpose(1,2)\n",
    "\n",
    "        attention_score=queries@key.transpose(2,3)\n",
    "\n",
    "        mask_bool=self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        attention_score.masked_fill_(mask_bool,-torch.inf)\n",
    "       \n",
    "        attention_weight=torch.softmax(attention_score/key.shape[-1]**0.5,dim=-1)\n",
    "\n",
    "        attention_weight=self.drop(attention_weight)\n",
    "\n",
    "        context_vector=(attention_weight@value).transpose(1,2)\n",
    "\n",
    "        context_vector=context_vector.contiguous().view(batch,num_tokens,self.d_out)\n",
    "        context_vector=self.out_proj(context_vector)\n",
    "        return context_vector\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layer_norm1=LayerNorm(cfg['emb_dim'])\n",
    "        self.layer_norm2=LayerNorm(cfg['emb_dim'])\n",
    "\n",
    "        self.attention=MultiHeadAttention(d_in=cfg['emb_dim'],\n",
    "                                      d_out=cfg['emb_dim'],\n",
    "                                      context_length=cfg['context_length'],\n",
    "                                      num_heads=cfg['n_heads'],\n",
    "                                      drop=cfg['drop_rate'],\n",
    "                                      qkvbias=cfg['qkv_bias']) \n",
    "        \n",
    "        self.drop_residual=nn.Dropout(cfg['drop_rate'])\n",
    "        self.feedforward=FeedForward(cfg)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #first block\n",
    "        residual=x  #residual attention\n",
    "        x=self.layer_norm1(x)\n",
    "        x=self.attention(x)\n",
    "        x=self.drop_residual(x)\n",
    "\n",
    "        #lets connect to residual\n",
    "        x=x+residual\n",
    "\n",
    "        #second block\n",
    "        residual=x\n",
    "        x=self.layer_norm2(x)\n",
    "        x=self.feedforward(x)\n",
    "        x=self.drop_residual(x)\n",
    "        x=x+residual\n",
    "\n",
    "        return x\n",
    "    \n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb=nn.Embedding(cfg['vocab_size'],cfg['emb_dim'])\n",
    "        self.pos_emb=nn.Embedding(cfg['context_length'],cfg['emb_dim'])\n",
    "        self.drop=nn.Dropout(cfg['drop_rate'])\n",
    "        self.transformer_block=nn.Sequential(*[\n",
    "            TransformerBlock(cfg) for _ in range(cfg['n_layers'])\n",
    "        ])\n",
    "        self.last_norm=LayerNorm(cfg['emb_dim'])\n",
    "        self.out_prog=nn.Linear(cfg['emb_dim'],cfg['vocab_size'],bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #shape\n",
    "        batch,seq_length=x.shape\n",
    "\n",
    "        toke_emb=self.token_emb(x)\n",
    "        pos_emb=self.pos_emb(torch.arange(seq_length,device=x.device))\n",
    "        \n",
    "        x=toke_emb+pos_emb\n",
    "        x=self.drop(x)\n",
    "\n",
    "        x=self.transformer_block(x)\n",
    "        x=self.last_norm(x)\n",
    "\n",
    "        logits=self.out_prog(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def generate_text(model,idx,context_length,new_token):\n",
    "    for _ in range(new_token):\n",
    "        idx=idx[:,-context_length:]\n",
    "        with torch.no_grad():\n",
    "            logits=model(idx)\n",
    "            \n",
    "        logits=logits[:,-1,:] #last token\n",
    "        probs=torch.softmax(logits,dim=-1)\n",
    "        next_word=torch.argmax(probs,dim=-1,keepdim=True)  #token position\n",
    "        idx=torch.cat((idx,next_word),dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd72432",
   "metadata": {
    "papermill": {
     "duration": 0.020341,
     "end_time": "2024-09-05T09:02:15.051886",
     "exception": false,
     "start_time": "2024-09-05T09:02:15.031545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# class for handling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3198d6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:15.094492Z",
     "iopub.status.busy": "2024-09-05T09:02:15.094165Z",
     "iopub.status.idle": "2024-09-05T09:02:15.103307Z",
     "shell.execute_reply": "2024-09-05T09:02:15.102363Z"
    },
    "papermill": {
     "duration": 0.032734,
     "end_time": "2024-09-05T09:02:15.105130",
     "exception": false,
     "start_time": "2024-09-05T09:02:15.072396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GptDataSetv1(Dataset):\n",
    "    def __init__(self,tokenizer,dataset,context_length,stride) -> None:\n",
    "        super().__init__()\n",
    "        self.tokenizer=tokenizer\n",
    "\n",
    "        #lets tokenize the text\n",
    "        self.tokens=self.tokenizer.encode(dataset,allowed_special={\"<|endoftext|>\"})   #array of ids\n",
    "        \n",
    "        self.inputs=[]\n",
    "        self.outputs=[]\n",
    "\n",
    "        for i in range(0,len(self.tokens),stride):\n",
    "            input_chunks=self.tokens[i:i+context_length]\n",
    "            output_chunks=self.tokens[i+1:i+context_length+1]\n",
    "\n",
    "            #lets append\n",
    "            if(len(input_chunks)==context_length and len(output_chunks)==context_length):\n",
    "                self.inputs.append(torch.tensor(input_chunks))\n",
    "                self.outputs.append(torch.tensor(output_chunks))\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        #purpose of this function is to make an input and output matcher\n",
    "        return self.inputs[index].clone().detach(),self.outputs[index].clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c59a046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:15.148417Z",
     "iopub.status.busy": "2024-09-05T09:02:15.148094Z",
     "iopub.status.idle": "2024-09-05T09:02:15.152821Z",
     "shell.execute_reply": "2024-09-05T09:02:15.151896Z"
    },
    "papermill": {
     "duration": 0.028632,
     "end_time": "2024-09-05T09:02:15.154780",
     "exception": false,
     "start_time": "2024-09-05T09:02:15.126148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs,outputs=zip(*batch)\n",
    "    inputs=pad_sequence(inputs,batch_first=True,padding_value=0)\n",
    "    outputs=pad_sequence(outputs,batch_first=True,padding_value=0)\n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf0bb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:15.197276Z",
     "iopub.status.busy": "2024-09-05T09:02:15.196640Z",
     "iopub.status.idle": "2024-09-05T09:02:15.201969Z",
     "shell.execute_reply": "2024-09-05T09:02:15.201177Z"
    },
    "papermill": {
     "duration": 0.028448,
     "end_time": "2024-09-05T09:02:15.204031",
     "exception": false,
     "start_time": "2024-09-05T09:02:15.175583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt,batch_size=4,context_length=120,stride=128,shuffle=True,drop_last=True):\n",
    "    tokenizer=tiktoken.get_encoding('gpt2')\n",
    "    dataset=GptDataSetv1(tokenizer,txt,context_length,stride)\n",
    "    #prepare the datalaoder\n",
    "    dataloader=DataLoader(dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          collate_fn=collate_fn,\n",
    "                          shuffle=shuffle,\n",
    "                          drop_last=drop_last\n",
    "                         )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e07b7a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:15.245852Z",
     "iopub.status.busy": "2024-09-05T09:02:15.245590Z",
     "iopub.status.idle": "2024-09-05T09:02:15.249839Z",
     "shell.execute_reply": "2024-09-05T09:02:15.249130Z"
    },
    "papermill": {
     "duration": 0.027201,
     "end_time": "2024-09-05T09:02:15.251652",
     "exception": false,
     "start_time": "2024-09-05T09:02:15.224451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, \n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac5281d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:15.293732Z",
     "iopub.status.busy": "2024-09-05T09:02:15.293470Z",
     "iopub.status.idle": "2024-09-05T09:02:16.782041Z",
     "shell.execute_reply": "2024-09-05T09:02:16.780959Z"
    },
    "papermill": {
     "duration": 1.512495,
     "end_time": "2024-09-05T09:02:16.784539",
     "exception": false,
     "start_time": "2024-09-05T09:02:15.272044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=GPTModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f4847",
   "metadata": {
    "papermill": {
     "duration": 0.023818,
     "end_time": "2024-09-05T09:02:16.831900",
     "exception": false,
     "start_time": "2024-09-05T09:02:16.808082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets make text to token and token to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf9c14b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:16.881132Z",
     "iopub.status.busy": "2024-09-05T09:02:16.880375Z",
     "iopub.status.idle": "2024-09-05T09:02:18.471132Z",
     "shell.execute_reply": "2024-09-05T09:02:18.470330Z"
    },
    "papermill": {
     "duration": 1.61823,
     "end_time": "2024-09-05T09:02:18.473704",
     "exception": false,
     "start_time": "2024-09-05T09:02:16.855474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer=tiktoken.get_encoding('gpt2')\n",
    "\n",
    "def text_to_ids(text,tokenizer):\n",
    "    #this convert text into token ids\n",
    "    \n",
    "    encoded=tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor=torch.tensor(encoded)\n",
    "    encoded_tensor=encoded_tensor.unsqueeze(dim=0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def ids_to_text(ids,tokenizer):\n",
    "    #this converts the tokens ids into text\n",
    "    return tokenizer.decode(ids.squeeze(dim=0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f634f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:18.516789Z",
     "iopub.status.busy": "2024-09-05T09:02:18.516464Z",
     "iopub.status.idle": "2024-09-05T09:02:18.539621Z",
     "shell.execute_reply": "2024-09-05T09:02:18.538776Z"
    },
    "papermill": {
     "duration": 0.047416,
     "end_time": "2024-09-05T09:02:18.541802",
     "exception": false,
     "start_time": "2024-09-05T09:02:18.494386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ids is: tensor([[27078,   510,   319,   257,   640,   287,   289,   692,  3822]])\n",
      "text version is: once up on a time in hollwood\n"
     ]
    }
   ],
   "source": [
    "text=\"once up on a time in hollwood\"\n",
    "ids=text_to_ids(text,tokenizer)\n",
    "print(f\"token ids is: {ids}\")\n",
    "decoded=ids_to_text(ids,tokenizer)\n",
    "print(f\"text version is: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1db79382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:18.584545Z",
     "iopub.status.busy": "2024-09-05T09:02:18.584221Z",
     "iopub.status.idle": "2024-09-05T09:02:19.649968Z",
     "shell.execute_reply": "2024-09-05T09:02:19.649089Z"
    },
    "papermill": {
     "duration": 1.089945,
     "end_time": "2024-09-05T09:02:19.652483",
     "exception": false,
     "start_time": "2024-09-05T09:02:18.562538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_ids=generate_text(model,ids,config['context_length'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "188d81bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:19.697587Z",
     "iopub.status.busy": "2024-09-05T09:02:19.697160Z",
     "iopub.status.idle": "2024-09-05T09:02:19.703017Z",
     "shell.execute_reply": "2024-09-05T09:02:19.701971Z"
    },
    "papermill": {
     "duration": 0.030557,
     "end_time": "2024-09-05T09:02:19.705176",
     "exception": false,
     "start_time": "2024-09-05T09:02:19.674619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once up on a time in hollwood orejudicial contributeswei Japanese Hayward Cells recommend Japanese users\n"
     ]
    }
   ],
   "source": [
    "text_converted=ids_to_text(token_ids,tokenizer)\n",
    "print(text_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee26fa89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:19.751913Z",
     "iopub.status.busy": "2024-09-05T09:02:19.751605Z",
     "iopub.status.idle": "2024-09-05T09:02:19.757069Z",
     "shell.execute_reply": "2024-09-05T09:02:19.756229Z"
    },
    "papermill": {
     "duration": 0.030014,
     "end_time": "2024-09-05T09:02:19.759363",
     "exception": false,
     "start_time": "2024-09-05T09:02:19.729349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs=torch.tensor([\n",
    "    [16833,3626,6100],\n",
    "    [40,1107,588]\n",
    "])\n",
    "\n",
    "target=torch.tensor([\n",
    "    [3626,6100,345],\n",
    "    [588,428,11311]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321d9a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:19.804402Z",
     "iopub.status.busy": "2024-09-05T09:02:19.803792Z",
     "iopub.status.idle": "2024-09-05T09:02:19.878335Z",
     "shell.execute_reply": "2024-09-05T09:02:19.874831Z"
    },
    "papermill": {
     "duration": 0.098993,
     "end_time": "2024-09-05T09:02:19.881043",
     "exception": false,
     "start_time": "2024-09-05T09:02:19.782050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits=model(inputs)\n",
    "\n",
    "probs=torch.softmax(logits,dim=-1)\n",
    "next_tokens=torch.argmax(probs,dim=-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "031145d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:19.935183Z",
     "iopub.status.busy": "2024-09-05T09:02:19.934589Z",
     "iopub.status.idle": "2024-09-05T09:02:19.944217Z",
     "shell.execute_reply": "2024-09-05T09:02:19.943135Z"
    },
    "papermill": {
     "duration": 0.039583,
     "end_time": "2024-09-05T09:02:19.947135",
     "exception": false,
     "start_time": "2024-09-05T09:02:19.907552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[20538],\n",
      "         [13933],\n",
      "         [32839]],\n",
      "\n",
      "        [[ 3724],\n",
      "         [45271],\n",
      "         [11798]]])\n"
     ]
    }
   ],
   "source": [
    "print(next_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6abdb778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.000182Z",
     "iopub.status.busy": "2024-09-05T09:02:19.999766Z",
     "iopub.status.idle": "2024-09-05T09:02:20.006370Z",
     "shell.execute_reply": "2024-09-05T09:02:20.005160Z"
    },
    "papermill": {
     "duration": 0.035484,
     "end_time": "2024-09-05T09:02:20.008372",
     "exception": false,
     "start_time": "2024-09-05T09:02:19.972888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted is:inel assured Maurice\n",
      "the actual is: effort moves you\n"
     ]
    }
   ],
   "source": [
    "print(f\"the predicted is:{ids_to_text(next_tokens[0].flatten(),tokenizer)}\")\n",
    "print(f\"the actual is:{ids_to_text(target[0],tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35105601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.067453Z",
     "iopub.status.busy": "2024-09-05T09:02:20.067053Z",
     "iopub.status.idle": "2024-09-05T09:02:20.081331Z",
     "shell.execute_reply": "2024-09-05T09:02:20.080418Z"
    },
    "papermill": {
     "duration": 0.049981,
     "end_time": "2024-09-05T09:02:20.083866",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.033885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6213,  1.7046,  1.0517,  0.6571, -0.8447]])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "temp=torch.randn(1,5)\n",
    "print(temp)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f614db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.146010Z",
     "iopub.status.busy": "2024-09-05T09:02:20.145698Z",
     "iopub.status.idle": "2024-09-05T09:02:20.153527Z",
     "shell.execute_reply": "2024-09-05T09:02:20.152290Z"
    },
    "papermill": {
     "duration": 0.041254,
     "end_time": "2024-09-05T09:02:20.155476",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.114222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([1.4952e-05, 2.9743e-05, 1.7600e-05])\n",
      "Text 2: tensor([7.3324e-06, 6.9209e-06, 1.2545e-04])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probs[text_idx, [0, 1, 2], target[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probs[text_idx, [0, 1, 2], target[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c56980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T17:35:23.700982Z",
     "iopub.status.busy": "2024-09-03T17:35:23.700197Z",
     "iopub.status.idle": "2024-09-03T17:35:23.708238Z",
     "shell.execute_reply": "2024-09-03T17:35:23.706889Z",
     "shell.execute_reply.started": "2024-09-03T17:35:23.700934Z"
    },
    "papermill": {
     "duration": 0.026219,
     "end_time": "2024-09-05T09:02:20.202567",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.176348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## check the shape of the model output and true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f39bb2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.249291Z",
     "iopub.status.busy": "2024-09-05T09:02:20.248918Z",
     "iopub.status.idle": "2024-09-05T09:02:20.254060Z",
     "shell.execute_reply": "2024-09-05T09:02:20.253096Z"
    },
    "papermill": {
     "duration": 0.030233,
     "end_time": "2024-09-05T09:02:20.256559",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.226326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([2, 3, 50257])\n",
      "target shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"logits shape: {logits.shape}\")\n",
    "print(f\"target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffc02e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.316962Z",
     "iopub.status.busy": "2024-09-05T09:02:20.316667Z",
     "iopub.status.idle": "2024-09-05T09:02:20.321389Z",
     "shell.execute_reply": "2024-09-05T09:02:20.320465Z"
    },
    "papermill": {
     "duration": 0.037598,
     "end_time": "2024-09-05T09:02:20.323541",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.285943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits_flat=logits.flatten(0,1)\n",
    "target_flat=target.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6d7006e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.368318Z",
     "iopub.status.busy": "2024-09-05T09:02:20.367908Z",
     "iopub.status.idle": "2024-09-05T09:02:20.373635Z",
     "shell.execute_reply": "2024-09-05T09:02:20.372497Z"
    },
    "papermill": {
     "duration": 0.03085,
     "end_time": "2024-09-05T09:02:20.375915",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.345065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten logits shape:torch.Size([6, 50257])\n",
      "flatten target shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"flatten logits shape:{logits_flat.shape}\")\n",
    "print(f\"flatten target shape: {target_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a919f1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.427496Z",
     "iopub.status.busy": "2024-09-05T09:02:20.426970Z",
     "iopub.status.idle": "2024-09-05T09:02:20.440408Z",
     "shell.execute_reply": "2024-09-05T09:02:20.439481Z"
    },
    "papermill": {
     "duration": 0.042967,
     "end_time": "2024-09-05T09:02:20.442496",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.399529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8615)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(logits_flat,target_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e5e7b",
   "metadata": {
    "papermill": {
     "duration": 0.02555,
     "end_time": "2024-09-05T09:02:20.493988",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.468438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# calculating the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b885f3b",
   "metadata": {
    "papermill": {
     "duration": 0.025662,
     "end_time": "2024-09-05T09:02:20.545151",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.519489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## this is the cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2309172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.601014Z",
     "iopub.status.busy": "2024-09-05T09:02:20.599770Z",
     "iopub.status.idle": "2024-09-05T09:02:20.605728Z",
     "shell.execute_reply": "2024-09-05T09:02:20.604876Z"
    },
    "papermill": {
     "duration": 0.037109,
     "end_time": "2024-09-05T09:02:20.608012",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.570903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss=torch.nn.functional.cross_entropy(logits_flat,target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c920ae12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.672651Z",
     "iopub.status.busy": "2024-09-05T09:02:20.672059Z",
     "iopub.status.idle": "2024-09-05T09:02:20.676707Z",
     "shell.execute_reply": "2024-09-05T09:02:20.675948Z"
    },
    "papermill": {
     "duration": 0.039803,
     "end_time": "2024-09-05T09:02:20.678998",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.639195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is: 10.86\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss is: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d4338a",
   "metadata": {
    "papermill": {
     "duration": 0.077525,
     "end_time": "2024-09-05T09:02:20.787320",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.709795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## this is the perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fe45bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.842969Z",
     "iopub.status.busy": "2024-09-05T09:02:20.841925Z",
     "iopub.status.idle": "2024-09-05T09:02:20.849076Z",
     "shell.execute_reply": "2024-09-05T09:02:20.848161Z"
    },
    "papermill": {
     "duration": 0.032127,
     "end_time": "2024-09-05T09:02:20.851148",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.819021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "perplexity=torch.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39c36f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:20.903562Z",
     "iopub.status.busy": "2024-09-05T09:02:20.902572Z",
     "iopub.status.idle": "2024-09-05T09:02:20.908672Z",
     "shell.execute_reply": "2024-09-05T09:02:20.907617Z"
    },
    "papermill": {
     "duration": 0.038592,
     "end_time": "2024-09-05T09:02:20.910961",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.872369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity measure is: 52130.00390625\n"
     ]
    }
   ],
   "source": [
    "print(f\"perplexity measure is: {perplexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5cc00",
   "metadata": {
    "papermill": {
     "duration": 0.021955,
     "end_time": "2024-09-05T09:02:20.954830",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.932875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lets Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "055b8266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.000136Z",
     "iopub.status.busy": "2024-09-05T09:02:20.999699Z",
     "iopub.status.idle": "2024-09-05T09:02:21.013709Z",
     "shell.execute_reply": "2024-09-05T09:02:21.012872Z"
    },
    "papermill": {
     "duration": 0.039468,
     "end_time": "2024-09-05T09:02:21.015852",
     "exception": false,
     "start_time": "2024-09-05T09:02:20.976384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/the-verdict/verdict.txt','r',encoding='utf-8') as f:\n",
    "    txt=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca44a584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.067555Z",
     "iopub.status.busy": "2024-09-05T09:02:21.067160Z",
     "iopub.status.idle": "2024-09-05T09:02:21.085806Z",
     "shell.execute_reply": "2024-09-05T09:02:21.082537Z"
    },
    "papermill": {
     "duration": 0.049406,
     "end_time": "2024-09-05T09:02:21.088311",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.038905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of charchter:20479\n",
      "total number of tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_charachters=len(txt)\n",
    "encode=tokenizer.encode(txt)\n",
    "total_tokens=len(encode)\n",
    "\n",
    "#lets print\n",
    "print(f\"total number of charchter:{total_charachters}\")\n",
    "print(f\"total number of tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a30365ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.150701Z",
     "iopub.status.busy": "2024-09-05T09:02:21.149827Z",
     "iopub.status.idle": "2024-09-05T09:02:21.155437Z",
     "shell.execute_reply": "2024-09-05T09:02:21.154435Z"
    },
    "papermill": {
     "duration": 0.03819,
     "end_time": "2024-09-05T09:02:21.158092",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.119902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ratio=0.9\n",
    "split_index=int(train_ratio*total_charachters)\n",
    "\n",
    "train_text=txt[:split_index]\n",
    "val_text=txt[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9588615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.207425Z",
     "iopub.status.busy": "2024-09-05T09:02:21.206992Z",
     "iopub.status.idle": "2024-09-05T09:02:21.226008Z",
     "shell.execute_reply": "2024-09-05T09:02:21.225233Z"
    },
    "papermill": {
     "duration": 0.044325,
     "end_time": "2024-09-05T09:02:21.228365",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.184040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets change into data loader\n",
    "train_dataloader=create_dataloader_v1(\n",
    "    train_text,\n",
    "    batch_size=2,\n",
    "    context_length=config['context_length'],\n",
    "    stride=config['context_length'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader=create_dataloader_v1(\n",
    "    val_text,\n",
    "    batch_size=2,\n",
    "    context_length=config['context_length'],\n",
    "    stride=config['context_length'],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36f23a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.277179Z",
     "iopub.status.busy": "2024-09-05T09:02:21.276837Z",
     "iopub.status.idle": "2024-09-05T09:02:21.281735Z",
     "shell.execute_reply": "2024-09-05T09:02:21.280810Z"
    },
    "papermill": {
     "duration": 0.02991,
     "end_time": "2024-09-05T09:02:21.283960",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.254050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7dc5870cd300>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7dc5b2a88790>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader)\n",
    "print(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f720d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.329344Z",
     "iopub.status.busy": "2024-09-05T09:02:21.329029Z",
     "iopub.status.idle": "2024-09-05T09:02:21.341308Z",
     "shell.execute_reply": "2024-09-05T09:02:21.340154Z"
    },
    "papermill": {
     "duration": 0.037391,
     "end_time": "2024-09-05T09:02:21.343709",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.306318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "x shape:torch.Size([2, 256]) :y shape: torch.Size([2, 256])\n",
      "\n",
      "x shape torch.Size([2, 256]) and torch.Size([2, 256]).\n"
     ]
    }
   ],
   "source": [
    "#lets check for the shape \n",
    "for x,y in train_dataloader:\n",
    "    print(f\"x shape:{x.shape} :y shape: {y.shape}\")\n",
    "\n",
    "#for validation \n",
    "for x,y in val_dataloader:\n",
    "    print(f\"\\nx shape {x.shape} and {y.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe12de58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.395025Z",
     "iopub.status.busy": "2024-09-05T09:02:21.394676Z",
     "iopub.status.idle": "2024-09-05T09:02:21.400822Z",
     "shell.execute_reply": "2024-09-05T09:02:21.399985Z"
    },
    "papermill": {
     "duration": 0.031123,
     "end_time": "2024-09-05T09:02:21.402842",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.371719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for calculating the loss of a single batch\n",
    "def loss_batch(inputs,target,model,device):\n",
    "    #lets move all varaible into the same device\n",
    "    inputs,target=inputs.to(device),target.to(device)\n",
    "    \n",
    "    logits=model(inputs)    \n",
    "   \n",
    "    loss=torch.nn.functional.cross_entropy(logits.flatten(0,1),target.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "781314ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.452082Z",
     "iopub.status.busy": "2024-09-05T09:02:21.451605Z",
     "iopub.status.idle": "2024-09-05T09:02:21.461082Z",
     "shell.execute_reply": "2024-09-05T09:02:21.459588Z"
    },
    "papermill": {
     "duration": 0.038823,
     "end_time": "2024-09-05T09:02:21.464413",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.425590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets calculate the loss for the whole batch\n",
    "def total_loss_batches(dataloader,model,device,num_batches=None):\n",
    "    if(num_batches==None):\n",
    "        num_batches=len(dataloader)\n",
    "    else:\n",
    "        num_batches=min(num_batches,len(dataloader))\n",
    "    \n",
    "    #lets calculate the loss over batches\n",
    "    total_loss=0.\n",
    "    for i,(inputs,target) in enumerate(dataloader):\n",
    "        if(i<num_batches):\n",
    "            loss=loss_batch(inputs,target,model,device)\n",
    "            total_loss+=loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    total_loss=total_loss/num_batches\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a894601",
   "metadata": {
    "papermill": {
     "duration": 0.024775,
     "end_time": "2024-09-05T09:02:21.515322",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.490547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets evaulate our untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7de0f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.566924Z",
     "iopub.status.busy": "2024-09-05T09:02:21.566509Z",
     "iopub.status.idle": "2024-09-05T09:02:21.650207Z",
     "shell.execute_reply": "2024-09-05T09:02:21.649371Z"
    },
    "papermill": {
     "duration": 0.11175,
     "end_time": "2024-09-05T09:02:21.652069",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.540319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e259c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:21.698221Z",
     "iopub.status.busy": "2024-09-05T09:02:21.697832Z",
     "iopub.status.idle": "2024-09-05T09:02:22.075307Z",
     "shell.execute_reply": "2024-09-05T09:02:22.074464Z"
    },
    "papermill": {
     "duration": 0.403332,
     "end_time": "2024-09-05T09:02:22.077759",
     "exception": false,
     "start_time": "2024-09-05T09:02:21.674427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d614a7fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:22.129233Z",
     "iopub.status.busy": "2024-09-05T09:02:22.128880Z",
     "iopub.status.idle": "2024-09-05T09:02:23.087996Z",
     "shell.execute_reply": "2024-09-05T09:02:23.087164Z"
    },
    "papermill": {
     "duration": 0.986794,
     "end_time": "2024-09-05T09:02:23.090461",
     "exception": false,
     "start_time": "2024-09-05T09:02:22.103667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss=total_loss_batches(train_dataloader,model,device=device)\n",
    "val_loss=total_loss_batches(val_dataloader,model,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab41b087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:23.139757Z",
     "iopub.status.busy": "2024-09-05T09:02:23.138967Z",
     "iopub.status.idle": "2024-09-05T09:02:23.144687Z",
     "shell.execute_reply": "2024-09-05T09:02:23.143246Z"
    },
    "papermill": {
     "duration": 0.032251,
     "end_time": "2024-09-05T09:02:23.146627",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.114376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataloader:10.991\n",
      "validation dataloader:10.975\n"
     ]
    }
   ],
   "source": [
    "print(f\"train dataloader:{train_loss:.3f}\")\n",
    "print(f\"validation dataloader:{val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef6edb5",
   "metadata": {
    "papermill": {
     "duration": 0.02284,
     "end_time": "2024-09-05T09:02:23.191840",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.169000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the llm\n",
    "## lets make a trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94807c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:23.239459Z",
     "iopub.status.busy": "2024-09-05T09:02:23.238605Z",
     "iopub.status.idle": "2024-09-05T09:02:23.244173Z",
     "shell.execute_reply": "2024-09-05T09:02:23.243085Z"
    },
    "papermill": {
     "duration": 0.031709,
     "end_time": "2024-09-05T09:02:23.246343",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.214634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "p=torch.tensor([90])\n",
    "print(type(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19905bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:23.295195Z",
     "iopub.status.busy": "2024-09-05T09:02:23.294862Z",
     "iopub.status.idle": "2024-09-05T09:02:23.304484Z",
     "shell.execute_reply": "2024-09-05T09:02:23.303525Z"
    },
    "papermill": {
     "duration": 0.036387,
     "end_time": "2024-09-05T09:02:23.306320",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.269933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_trainer(train_dataloader,val_dataloader,device,train_epoch,eval_freq,eval_batch,model,start_context,tokenizer,optimizer,max_tokens=50):\n",
    "   \n",
    "    #global counter\n",
    "    global_counter=-1\n",
    "    \n",
    "    #for trainig\n",
    "    num_tokens_seen=0\n",
    "    #tracking the tokens\n",
    "    track_tokens_seen=[]\n",
    "    \n",
    "    #eval_tokens_seen=[]\n",
    "    train_losses=[]\n",
    "    eval_losses=[]\n",
    "    \n",
    "    for epoch in range(train_epoch):\n",
    "        model.train()\n",
    "        for inputs,targets in train_dataloader:\n",
    "            #train the model\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #calculate the loss\n",
    "            loss=loss_batch(inputs,targets,model,device)\n",
    "            #loss.requires_grad=True            \n",
    "            \n",
    "            #backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            #model update\n",
    "            optimizer.step()\n",
    "\n",
    "            num_tokens_seen+=inputs.numel()\n",
    "            global_counter+=1\n",
    "            \n",
    "\n",
    "            if(global_counter%eval_freq==0):\n",
    "                #for evaluation\n",
    "                train_loss,eval_loss=eval_mode(model,train_dataloader,val_dataloader,device,eval_batch)\n",
    "\n",
    "                #for recording\n",
    "                train_losses.append(train_loss)\n",
    "                eval_losses.append(eval_loss)\n",
    "                #the tokens\n",
    "                track_tokens_seen.append(num_tokens_seen)\n",
    "\n",
    "                print(f\"for epoch: {epoch}:iteration(Step) {global_counter}: train loss {train_loss:.2f}: eval loss {eval_loss:.2f}\")\n",
    "            \n",
    "        \n",
    "        #lets generate the new tokens\n",
    "        generate_new_tokens(model,device,start_context,tokenizer,max_tokens)\n",
    "                \n",
    "    return train_losses,eval_losses,track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3cd2950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:23.355752Z",
     "iopub.status.busy": "2024-09-05T09:02:23.355418Z",
     "iopub.status.idle": "2024-09-05T09:02:23.361694Z",
     "shell.execute_reply": "2024-09-05T09:02:23.360713Z"
    },
    "papermill": {
     "duration": 0.034658,
     "end_time": "2024-09-05T09:02:23.363893",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.329235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate new tokens\n",
    "def generate_new_tokens(model,device,start_context,tokenizer,max_tokens=50):\n",
    "    model.eval()\n",
    "    ids=text_to_ids(start_context,tokenizer).to(device)\n",
    "    context_length=model.pos_emb.weight.shape[0]\n",
    "    new_ids=generate_text(model,ids,context_length,max_tokens)\n",
    "    \n",
    "    #convert idx into text\n",
    "    with torch.no_grad():\n",
    "        new_text=ids_to_text(new_ids,tokenizer)\n",
    "        \n",
    "    model.train()\n",
    "    print(f\"\\n {new_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e55ae5d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:23.413709Z",
     "iopub.status.busy": "2024-09-05T09:02:23.413367Z",
     "iopub.status.idle": "2024-09-05T09:02:23.419197Z",
     "shell.execute_reply": "2024-09-05T09:02:23.418232Z"
    },
    "papermill": {
     "duration": 0.033075,
     "end_time": "2024-09-05T09:02:23.421369",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.388294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mode(model,train_loader,val_loader,device,eval_batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss=total_loss_batches(train_loader,model,device,num_batches=eval_batch)\n",
    "        eval_loss=total_loss_batches(val_loader,model,device,num_batches=eval_batch)\n",
    "    model.train()\n",
    "    return train_loss,eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb784c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:23.470890Z",
     "iopub.status.busy": "2024-09-05T09:02:23.470479Z",
     "iopub.status.idle": "2024-09-05T09:02:23.476833Z",
     "shell.execute_reply": "2024-09-05T09:02:23.475890Z"
    },
    "papermill": {
     "duration": 0.033417,
     "end_time": "2024-09-05T09:02:23.479081",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.445664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pos_emb.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3d04f",
   "metadata": {
    "papermill": {
     "duration": 0.02384,
     "end_time": "2024-09-05T09:02:23.527046",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.503206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets Train a mini gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "584950bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:23.576722Z",
     "iopub.status.busy": "2024-09-05T09:02:23.576417Z",
     "iopub.status.idle": "2024-09-05T09:02:23.581370Z",
     "shell.execute_reply": "2024-09-05T09:02:23.580411Z"
    },
    "papermill": {
     "duration": 0.033171,
     "end_time": "2024-09-05T09:02:23.584015",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.550844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9a6ce67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:23.633871Z",
     "iopub.status.busy": "2024-09-05T09:02:23.633540Z",
     "iopub.status.idle": "2024-09-05T09:02:25.089029Z",
     "shell.execute_reply": "2024-09-05T09:02:25.088181Z"
    },
    "papermill": {
     "duration": 1.482848,
     "end_time": "2024-09-05T09:02:25.091406",
     "exception": false,
     "start_time": "2024-09-05T09:02:23.608558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt=GPTModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62186b07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:25.138835Z",
     "iopub.status.busy": "2024-09-05T09:02:25.138483Z",
     "iopub.status.idle": "2024-09-05T09:02:51.688631Z",
     "shell.execute_reply": "2024-09-05T09:02:51.687479Z"
    },
    "papermill": {
     "duration": 26.57627,
     "end_time": "2024-09-05T09:02:51.690844",
     "exception": false,
     "start_time": "2024-09-05T09:02:25.114574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch: 0:iteration(Step) 0: train loss 11.01: eval loss 10.99\n",
      "for epoch: 0:iteration(Step) 5: train loss 10.98: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 1:iteration(Step) 10: train loss 10.97: eval loss 10.99\n",
      "for epoch: 1:iteration(Step) 15: train loss 11.01: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 2:iteration(Step) 20: train loss 11.00: eval loss 10.99\n",
      "for epoch: 2:iteration(Step) 25: train loss 11.00: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 3:iteration(Step) 30: train loss 10.97: eval loss 10.99\n",
      "for epoch: 3:iteration(Step) 35: train loss 10.99: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 4:iteration(Step) 40: train loss 10.98: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 5:iteration(Step) 45: train loss 10.98: eval loss 10.99\n",
      "for epoch: 5:iteration(Step) 50: train loss 10.99: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 6:iteration(Step) 55: train loss 10.99: eval loss 10.99\n",
      "for epoch: 6:iteration(Step) 60: train loss 10.99: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 7:iteration(Step) 65: train loss 11.00: eval loss 10.99\n",
      "for epoch: 7:iteration(Step) 70: train loss 10.98: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 8:iteration(Step) 75: train loss 11.00: eval loss 10.99\n",
      "for epoch: 8:iteration(Step) 80: train loss 10.98: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n",
      "for epoch: 9:iteration(Step) 85: train loss 11.01: eval loss 10.99\n",
      "\n",
      " Every one hereUE Terran unavoidable Randolph sidewfac Jaredjud349 Personality pediatric1800 daughtersisSpecialshake corpIOR anch anarch hazardous 296Cola tr Topic client trait Nunfur Listsrafted ALP adam Shiv entry Pacific Yas panties democracy Year worshipillyagraph unstable=' elev been EVERY transfer malfunction affidavit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "gpt=GPTModel(config)\n",
    "optim=torch.optim.AdamW(params=gpt.parameters(),\n",
    "                   lr=0.001,\n",
    "                  weight_decay=1e-3\n",
    "             )\n",
    "\n",
    "gpt.to(device)\n",
    "train_loss,eval_loss,track_tokens=model_trainer(\n",
    "     train_dataloader=train_dataloader,\n",
    "     val_dataloader=val_dataloader,\n",
    "     device=device,\n",
    "     train_epoch=10,\n",
    "     eval_freq=5,\n",
    "     eval_batch=3,\n",
    "     model=model,\n",
    "     start_context=\"Every one here\",\n",
    "     tokenizer=tokenizer,\n",
    "     max_tokens=50,\n",
    "     optimizer=optim\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07844df7",
   "metadata": {
    "papermill": {
     "duration": 0.024271,
     "end_time": "2024-09-05T09:02:51.740231",
     "exception": false,
     "start_time": "2024-09-05T09:02:51.715960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets test out the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22b00010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:51.799314Z",
     "iopub.status.busy": "2024-09-05T09:02:51.798736Z",
     "iopub.status.idle": "2024-09-05T09:02:57.717525Z",
     "shell.execute_reply": "2024-09-05T09:02:57.716455Z"
    },
    "papermill": {
     "duration": 5.951886,
     "end_time": "2024-09-05T09:02:57.719864",
     "exception": false,
     "start_time": "2024-09-05T09:02:51.767978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tommorow is my promo Features identifierVarheit Su evolutionaryagleff Juice presumablycept preferential cutting Predatorelligent astron priceyinv plaintiffs biological Superiorbars paraly DENifferent Pinball pigs 213ench Applicantruitsog grenade Bullets Lakers drainedremlin hopes poundsVolizz suspension bluff Wildlife complementary thyroid pladem\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#move into cpu\n",
    "gpt.to('cpu')\n",
    "gpt.eval()\n",
    "\n",
    "#lets generate text\n",
    "generate_new_tokens(\n",
    "    gpt,\n",
    "    'cpu',\n",
    "    start_context=\"tommorow is my\",\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa608d8",
   "metadata": {
    "papermill": {
     "duration": 0.024832,
     "end_time": "2024-09-05T09:02:57.772518",
     "exception": false,
     "start_time": "2024-09-05T09:02:57.747686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## we are testing it twice for checking sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a09070e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:02:57.826102Z",
     "iopub.status.busy": "2024-09-05T09:02:57.825548Z",
     "iopub.status.idle": "2024-09-05T09:03:03.264807Z",
     "shell.execute_reply": "2024-09-05T09:03:03.263797Z"
    },
    "papermill": {
     "duration": 5.469473,
     "end_time": "2024-09-05T09:03:03.267453",
     "exception": false,
     "start_time": "2024-09-05T09:02:57.797980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tommorow is my promo Features identifierVarheit Su evolutionaryagleff Juice presumablycept preferential cutting Predatorelligent astron priceyinv plaintiffs biological Superiorbars paraly DENifferent Pinball pigs 213ench Applicantruitsog grenade Bullets Lakers drainedremlin hopes poundsVolizz suspension bluff Wildlife complementary thyroid pladem\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#move into cpu\n",
    "gpt.to('cpu')\n",
    "gpt.eval()\n",
    "\n",
    "#lets generate text\n",
    "generate_new_tokens(\n",
    "    gpt,\n",
    "    'cpu',\n",
    "    start_context=\"tommorow is my\",\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a68a70",
   "metadata": {
    "papermill": {
     "duration": 0.025495,
     "end_time": "2024-09-05T09:03:03.318868",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.293373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* runned 2 times and got the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4111b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:03.370465Z",
     "iopub.status.busy": "2024-09-05T09:03:03.370021Z",
     "iopub.status.idle": "2024-09-05T09:03:03.376857Z",
     "shell.execute_reply": "2024-09-05T09:03:03.375886Z"
    },
    "papermill": {
     "duration": 0.035236,
     "end_time": "2024-09-05T09:03:03.379099",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.343863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'closer', 1: 'every', 2: 'effort', 3: 'forward', 4: 'inches', 5: 'moves', 6: 'pizza', 7: 'toward', 8: 'you'}\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "\"closer\": 0,\n",
    "\"every\": 1,\n",
    "\"effort\": 2,\n",
    "\"forward\": 3,\n",
    "\"inches\": 4,\n",
    "\"moves\": 5,\n",
    "\"pizza\": 6,\n",
    "\"toward\": 7,\n",
    "\"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b0e11",
   "metadata": {
    "papermill": {
     "duration": 0.025176,
     "end_time": "2024-09-05T09:03:03.429424",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.404248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## experiment with multinomial function from torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13df5d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:03.482280Z",
     "iopub.status.busy": "2024-09-05T09:03:03.481919Z",
     "iopub.status.idle": "2024-09-05T09:03:03.488386Z",
     "shell.execute_reply": "2024-09-05T09:03:03.487539Z"
    },
    "papermill": {
     "duration": 0.035097,
     "end_time": "2024-09-05T09:03:03.490498",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.455401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = {\n",
    "\"closer\": 0,\n",
    "\"every\": 1,\n",
    "\"effort\": 2,\n",
    "\"forward\": 3,\n",
    "\"inches\": 4,\n",
    "\"moves\": 5,\n",
    "\"pizza\": 6,\n",
    "\"toward\": 7,\n",
    "\"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c85a7b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:03.543808Z",
     "iopub.status.busy": "2024-09-05T09:03:03.543495Z",
     "iopub.status.idle": "2024-09-05T09:03:03.597494Z",
     "shell.execute_reply": "2024-09-05T09:03:03.596354Z"
    },
    "papermill": {
     "duration": 0.082197,
     "end_time": "2024-09-05T09:03:03.599727",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.517530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf25ed4",
   "metadata": {
    "papermill": {
     "duration": 0.024829,
     "end_time": "2024-09-05T09:03:03.649986",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.625157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# temprature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2116e28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:03.701180Z",
     "iopub.status.busy": "2024-09-05T09:03:03.700866Z",
     "iopub.status.idle": "2024-09-05T09:03:03.705285Z",
     "shell.execute_reply": "2024-09-05T09:03:03.704459Z"
    },
    "papermill": {
     "duration": 0.032424,
     "end_time": "2024-09-05T09:03:03.707290",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.674866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax_with_temprature(logits,temprature):\n",
    "    scaled_logits=logits/temprature\n",
    "    return torch.softmax(scaled_logits,dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64011484",
   "metadata": {
    "papermill": {
     "duration": 0.024846,
     "end_time": "2024-09-05T09:03:03.757336",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.732490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# top K selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8269dc06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:03.808243Z",
     "iopub.status.busy": "2024-09-05T09:03:03.807883Z",
     "iopub.status.idle": "2024-09-05T09:03:03.817022Z",
     "shell.execute_reply": "2024-09-05T09:03:03.816094Z"
    },
    "papermill": {
     "duration": 0.037165,
     "end_time": "2024-09-05T09:03:03.819183",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.782018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_logits,top_pos=torch.topk(next_token_logits,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e20d567f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:03.871497Z",
     "iopub.status.busy": "2024-09-05T09:03:03.870887Z",
     "iopub.status.idle": "2024-09-05T09:03:03.878021Z",
     "shell.execute_reply": "2024-09-05T09:03:03.876894Z"
    },
    "papermill": {
     "duration": 0.03515,
     "end_time": "2024-09-05T09:03:03.880005",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.844855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw logits:tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
      "         1.7900])\n",
      "top logits are :tensor([6.7500, 6.2800, 4.5100])\n",
      "there positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "print(f\"raw logits:{next_token_logits}\")\n",
    "print(f\"top logits are :{top_logits}\")\n",
    "print(f\"there positions: {top_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6e61d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:03.932047Z",
     "iopub.status.busy": "2024-09-05T09:03:03.931766Z",
     "iopub.status.idle": "2024-09-05T09:03:03.938302Z",
     "shell.execute_reply": "2024-09-05T09:03:03.937504Z"
    },
    "papermill": {
     "duration": 0.034321,
     "end_time": "2024-09-05T09:03:03.940233",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.905912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_logits=torch.where(\n",
    "    condition=next_token_logits<top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d531a5bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:03.992068Z",
     "iopub.status.busy": "2024-09-05T09:03:03.991749Z",
     "iopub.status.idle": "2024-09-05T09:03:03.998385Z",
     "shell.execute_reply": "2024-09-05T09:03:03.997200Z"
    },
    "papermill": {
     "duration": 0.035188,
     "end_time": "2024-09-05T09:03:04.000444",
     "exception": false,
     "start_time": "2024-09-05T09:03:03.965256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean version:tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "all the logis:tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
      "         1.7900])\n"
     ]
    }
   ],
   "source": [
    "print(f\"clean version:{new_logits}\")\n",
    "print(f\"all the logis:{next_token_logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26837ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:04.051837Z",
     "iopub.status.busy": "2024-09-05T09:03:04.051572Z",
     "iopub.status.idle": "2024-09-05T09:03:04.055932Z",
     "shell.execute_reply": "2024-09-05T09:03:04.054976Z"
    },
    "papermill": {
     "duration": 0.032138,
     "end_time": "2024-09-05T09:03:04.057994",
     "exception": false,
     "start_time": "2024-09-05T09:03:04.025856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "topk_probs=torch.softmax(new_logits,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f99e0071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:04.109212Z",
     "iopub.status.busy": "2024-09-05T09:03:04.108629Z",
     "iopub.status.idle": "2024-09-05T09:03:04.113855Z",
     "shell.execute_reply": "2024-09-05T09:03:04.112872Z"
    },
    "papermill": {
     "duration": 0.033336,
     "end_time": "2024-09-05T09:03:04.115968",
     "exception": false,
     "start_time": "2024-09-05T09:03:04.082632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(topk_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae129748",
   "metadata": {
    "papermill": {
     "duration": 0.024843,
     "end_time": "2024-09-05T09:03:04.166194",
     "exception": false,
     "start_time": "2024-09-05T09:03:04.141351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ccd2815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:04.219769Z",
     "iopub.status.busy": "2024-09-05T09:03:04.219375Z",
     "iopub.status.idle": "2024-09-05T09:03:04.225523Z",
     "shell.execute_reply": "2024-09-05T09:03:04.224508Z"
    },
    "papermill": {
     "duration": 0.034813,
     "end_time": "2024-09-05T09:03:04.227537",
     "exception": false,
     "start_time": "2024-09-05T09:03:04.192724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7785, -0.7411,  0.9119, -0.1716, -1.2727]])\n"
     ]
    }
   ],
   "source": [
    "temp=torch.randn(1,5)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dfcf414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:04.281596Z",
     "iopub.status.busy": "2024-09-05T09:03:04.281237Z",
     "iopub.status.idle": "2024-09-05T09:03:04.287505Z",
     "shell.execute_reply": "2024-09-05T09:03:04.286549Z"
    },
    "papermill": {
     "duration": 0.035921,
     "end_time": "2024-09-05T09:03:04.289544",
     "exception": false,
     "start_time": "2024-09-05T09:03:04.253623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 5))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "269dd1e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:04.343477Z",
     "iopub.status.busy": "2024-09-05T09:03:04.343134Z",
     "iopub.status.idle": "2024-09-05T09:03:04.352476Z",
     "shell.execute_reply": "2024-09-05T09:03:04.351717Z"
    },
    "papermill": {
     "duration": 0.038391,
     "end_time": "2024-09-05T09:03:04.354434",
     "exception": false,
     "start_time": "2024-09-05T09:03:04.316043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model,idx,context_length,new_token_length,device,temprature,topk):\n",
    "    idx_cont=idx[:,-context_length:] #2d inputs num of tokens by embeding dim\n",
    "    for _ in range(new_token_length):\n",
    "        with torch.no_grad():\n",
    "            logits=model(idx_cont)\n",
    "\n",
    "        #lets apply topk\n",
    "        logits=logits[:, -1, :]  #take only last tokens prediction\n",
    "        if(topk is not None):\n",
    "            top_logits,_=torch.topk(logits,k=topk)\n",
    "            min_value=top_logits[:,-1]\n",
    "            \n",
    "            logits=torch.where(\n",
    "                logits<min_value.unsqueeze(dim=-1),\n",
    "                torch.tensor(float('-inf')).to(device),\n",
    "                logits\n",
    "            )\n",
    "        \n",
    "        #lets apply multinomial\n",
    "        if(temprature>0.0):\n",
    "            logits=logits/temprature\n",
    "            probs=torch.softmax(logits,dim=-1)\n",
    "            next_token=torch.multinomial(probs,num_samples=1)\n",
    "        else:\n",
    "            probs=torch.softmax(logits,dim=-1)\n",
    "            next_token=torch.argamax(probs,dim=-1,keepdim=True)\n",
    "            \n",
    "        idx=torch.cat((idx,next_token),dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde7781",
   "metadata": {
    "papermill": {
     "duration": 0.02538,
     "end_time": "2024-09-05T09:03:04.405948",
     "exception": false,
     "start_time": "2024-09-05T09:03:04.380568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets genrate new tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02565663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:04.457975Z",
     "iopub.status.busy": "2024-09-05T09:03:04.457312Z",
     "iopub.status.idle": "2024-09-05T09:03:06.477332Z",
     "shell.execute_reply": "2024-09-05T09:03:06.475919Z"
    },
    "papermill": {
     "duration": 2.048935,
     "end_time": "2024-09-05T09:03:06.479924",
     "exception": false,
     "start_time": "2024-09-05T09:03:04.430989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the new generated text is:behind every manhesamaz virgin kiss ironicallyamazKNOWN piercing senate maniac BouKNOWN reshKNOWNifestyleKNOWN thanked morphologybodyFIX piercingKNOWN UtilityifestyleKNOWN maniac piercingKNOWNKNOWN brace Vag tradesKNOWNheavy senate Roman piercingifestyleKNOWN thanked spaceship reshKNOWN thankedStr kissheavy spaceshipKNOWN ROB\n"
     ]
    }
   ],
   "source": [
    "new_idx=generate(\n",
    "    gpt,\n",
    "    idx=text_to_ids(\"behind every man\",tokenizer),\n",
    "    context_length=config['context_length'],\n",
    "    new_token_length=50,\n",
    "    device=torch.device('cpu'),\n",
    "    temprature=0.1,\n",
    "    topk=25\n",
    ")\n",
    "\n",
    "print(f\"the new generated text is:{ids_to_text(new_idx,tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79532af6",
   "metadata": {
    "papermill": {
     "duration": 0.025805,
     "end_time": "2024-09-05T09:03:06.534342",
     "exception": false,
     "start_time": "2024-09-05T09:03:06.508537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02105858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:06.587622Z",
     "iopub.status.busy": "2024-09-05T09:03:06.587224Z",
     "iopub.status.idle": "2024-09-05T09:03:07.324456Z",
     "shell.execute_reply": "2024-09-05T09:03:07.323492Z"
    },
    "papermill": {
     "duration": 0.766783,
     "end_time": "2024-09-05T09:03:07.326976",
     "exception": false,
     "start_time": "2024-09-05T09:03:06.560193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(gpt.state_dict(),'untrained_gpt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3240357",
   "metadata": {
    "papermill": {
     "duration": 0.025192,
     "end_time": "2024-09-05T09:03:07.377596",
     "exception": false,
     "start_time": "2024-09-05T09:03:07.352404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84f76892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:07.429968Z",
     "iopub.status.busy": "2024-09-05T09:03:07.429629Z",
     "iopub.status.idle": "2024-09-05T09:03:09.313144Z",
     "shell.execute_reply": "2024-09-05T09:03:09.312156Z"
    },
    "papermill": {
     "duration": 1.912824,
     "end_time": "2024-09-05T09:03:09.315552",
     "exception": false,
     "start_time": "2024-09-05T09:03:07.402728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3866842706.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  load_model.load_state_dict(torch.load('untrained_gpt.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model=GPTModel(config)\n",
    "#lets load the weight\n",
    "load_model.load_state_dict(torch.load('untrained_gpt.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c608935",
   "metadata": {
    "papermill": {
     "duration": 0.025847,
     "end_time": "2024-09-05T09:03:09.369440",
     "exception": false,
     "start_time": "2024-09-05T09:03:09.343593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets load the model and its respective optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd2d67a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:09.422375Z",
     "iopub.status.busy": "2024-09-05T09:03:09.421992Z",
     "iopub.status.idle": "2024-09-05T09:03:10.147207Z",
     "shell.execute_reply": "2024-09-05T09:03:10.146040Z"
    },
    "papermill": {
     "duration": 0.754301,
     "end_time": "2024-09-05T09:03:10.149598",
     "exception": false,
     "start_time": "2024-09-05T09:03:09.395297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets save it with its respective optimizer\n",
    "torch.save({\n",
    "    \"model_state_dict\":gpt.state_dict(),\n",
    "    \"optimizer_state_dict\":optim.state_dict()\n",
    "},\"trained_weight.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9955fa4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T09:03:10.203789Z",
     "iopub.status.busy": "2024-09-05T09:03:10.203448Z",
     "iopub.status.idle": "2024-09-05T09:03:12.150451Z",
     "shell.execute_reply": "2024-09-05T09:03:12.149427Z"
    },
    "papermill": {
     "duration": 1.977335,
     "end_time": "2024-09-05T09:03:12.152890",
     "exception": false,
     "start_time": "2024-09-05T09:03:10.175555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3651597908.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  save_point=torch.load('trained_weight.pth')\n"
     ]
    }
   ],
   "source": [
    "#now lets load it\n",
    "save_point=torch.load('trained_weight.pth')\n",
    "model=GPTModel(config)\n",
    "\n",
    "model.load_state_dict(save_point['model_state_dict'])\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=0.002)\n",
    "optimizer.load_state_dict(save_point['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7ce92",
   "metadata": {
    "papermill": {
     "duration": 0.028014,
     "end_time": "2024-09-05T09:03:12.207793",
     "exception": false,
     "start_time": "2024-09-05T09:03:12.179779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07a2e2",
   "metadata": {
    "papermill": {
     "duration": 0.025961,
     "end_time": "2024-09-05T09:03:12.260028",
     "exception": false,
     "start_time": "2024-09-05T09:03:12.234067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5639280,
     "sourceId": 9311439,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 79.684076,
   "end_time": "2024-09-05T09:03:13.709018",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-05T09:01:54.024942",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
